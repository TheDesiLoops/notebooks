{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In this blog post, we will have a look at how can we build AI chat with youtube videos. \n",
        "\n",
        "The main problem that I wanted to solve was, sometimes I need to watch a long videos to get the information that I need. So, I thought why not build a chatbot that can help me with that. This would not only save my time but also help me to get the information that I need quickly.\n",
        "\n",
        "Checkout this blog in video \n",
        "\n",
        "[![AI Workshop - Chat with videos](https://img.youtube.com/vi/ISCLsXS9Sns/0.jpg)](https://www.youtube.com/watch?v=ISCLsXS9Sns \"AI Workshop - Chat with videos\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets install the pytubefix library. We will be using this library to get the audio from the video.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytubefix\n",
            "  Downloading pytubefix-6.16.3-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.7/78.7 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytubefix\n",
            "Successfully installed pytubefix-6.16.3\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install pytubefix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "I have choosen a video that explains the concept of pointers in C language. I will be using this video to build the chatbot.\n",
        "\n",
        "Checkout the video here\n",
        "\n",
        "[![#23 C Pointers | C Programming For Beginners](https://img.youtube.com/vi/KGhacRRMnDw/0.jpg)](https://www.youtube.com/watch?v=KGhacRRMnDw \"#23 C Pointers | C Programming For Beginners\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets download the audio from the video."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "from pytubefix import YouTube\n",
        "yt = YouTube(\"https://www.youtube.com/watch?v=KGhacRRMnDw\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/rajesh/Documents/Work/personal/ai/notebooks/video-chat/23 C Pointers  C Programming For Beginners.mp4'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ys = yt.streams.get_audio_only()\n",
        "ys.download()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, lets install the openai library. We will be first transcribing the audio to text using the openai library and then use the LLM to generate coherent responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.47.1-py3-none-any.whl (375 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m375.6/375.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting anyio<5,>=3.5.0 (from openai)\n",
            "  Downloading anyio-4.6.0-py3-none-any.whl (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distro<2,>=1.7.0 (from openai)\n",
            "  Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Using cached httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "Collecting jiter<1,>=0.4.0 (from openai)\n",
            "  Using cached jiter-0.5.0-cp311-cp311-macosx_11_0_arm64.whl (299 kB)\n",
            "Collecting pydantic<3,>=1.9.0 (from openai)\n",
            "  Using cached pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
            "Collecting sniffio (from openai)\n",
            "  Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
            "Collecting tqdm>4 (from openai)\n",
            "  Using cached tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in ./env/lib/python3.11/site-packages (from openai) (4.12.2)\n",
            "Collecting idna>=2.8 (from anyio<5,>=3.5.0->openai)\n",
            "  Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
            "Collecting certifi (from httpx<1,>=0.23.0->openai)\n",
            "  Using cached certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Using cached httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->openai)\n",
            "  Using cached annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Collecting pydantic-core==2.23.4 (from pydantic<3,>=1.9.0->openai)\n",
            "  Using cached pydantic_core-2.23.4-cp311-cp311-macosx_11_0_arm64.whl (1.8 MB)\n",
            "Installing collected packages: tqdm, sniffio, pydantic-core, jiter, idna, h11, distro, certifi, annotated-types, pydantic, httpcore, anyio, httpx, openai\n",
            "Successfully installed annotated-types-0.7.0 anyio-4.6.0 certifi-2024.8.30 distro-1.9.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 idna-3.10 jiter-0.5.0 openai-1.47.1 pydantic-2.9.2 pydantic-core-2.23.4 sniffio-1.3.1 tqdm-4.66.5\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "In the next step, I am setting up the openai api key, in the jupyter notebook. If you are not using jupyter notebook, you can set the api key in the environment variable."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "import getpass\n",
        "openai_key = getpass.getpass(\"Enter your OpenAI key: \")\n",
        "\n",
        "!export OPENAI_API_KEY=$openai_key"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, we do the transcription of the audio to text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "What's up guys? Welcome back to this series on C programming. In this video, we'll learn about pointers in C. More specifically, we'll learn to work directly with computer memory address with the help of pointers. So let's get started. Pointer is one of the main features that make C programming so powerful. It allows us to work directly with the computer memory. Before we learn about pointers, let's first learn about addresses. In C programming, whenever we declare a variable, a space will be allocated in the memory for the variable and C allows us to access the address of the variable. We use the ampersand symbol with the variable name to access the memory address. Let's see an example. You might be familiar with the basic structure of C program. Now I'll create an integer variable, age, so int age, and I'll assign value 25 to this. Now let's use ampersand symbol to access the address where the age variable is stored. So printf %p, ampersand age. Here I have used %p format specifier to print the address. Now let me run this code. Here you can see we get this output which is the memory address where 25 is located. When you copy and run the exact same code, you may get different output because the output is based on the location where the variable is stored and it varies device to device. If you remember, we have used ampersand symbol with scanf like this, like ampersand age. So usually we use this ampersand age with scanf while taking input from the user. This is because with scanf we are instructing the compiler to store the input value at the memory address specified by this ampersand age. Now that you know about memory addresses, let's get back to pointers. Just like a regular variable, a pointer is also a variable. However, a pointer variable stores the memory addresses of the variable, not the actual value. Let's now see how we can create pointers. So I'll create pointer int asterix ptr. Here ptr is a pointer variable. Let me create a regular variable and compare these two. So I'll create int var. When comparing these two, you can see the only difference between these two is this asterix symbol. Now let's see how we can assign value to a pointer variable. Here is our code from our earlier program. Now let me create a pointer variable int asterix ptr. As we know, a pointer variable stores a memory address of a variable and we also know that ampersand age gives the memory address. So when we assign ampersand age to the pointer variable, the pointer variable should store the memory address of the age variable. So let's do that. Now I'll assign this pointer to the address of age variable and I'll print this using printf statement comma ptr. Now let me run this code. Here you can see we get the same result for both ampersand age and ptr. By the way, if you're watching this, there is a good chance you want to improve your skills in C programming. Lucky for you, we have a mobile app that provides a well-structured C programming course with certification at the end and you can use the app alongside the video to practice on the build and compiler. Our course is free so download now by scanning this QR code or click the link in the video description. We can also access the value of a variable using the pointer. Let's see an example. In our code from our earlier example, I'll remove this print statement and I'll modify this print statement here address colon x space n. Now let's print the value using ptr pointer. I'll use printf statement printf value colon percent d comma asterix ptr. Here asterix ptr gives the value stored in the ptr address and since the value is in integer, I have used percent d for my specifier. Now let me run this code. As you can see, we have successfully accessed the value using the pointer variable. Remember ptr is a pointer that stores the memory address and asterix ptr gives the value stored in the memory address pointed by this ptr. In our last example, we saw that we can access value of a variable using pointer variable. Similarly, we can also change the value of a variable using pointer variable. Let's see an example. Here we have our code from our earlier program. Here in this program, I'll remove these two print statements. Now let's use pointer variable to change the value from age 25 to 31. 25 to 31. So I'll use pointer and assign value 31. Since we know asterix ptr gives the value pointed by the ptr address, so this code assigns a new value to the memory address pointed by the ptr variable. Now let's print the value of the age variable. I'll use printf statement percent d comma age and I'll run this. Here you can see the value of age variable is changed to 31. This is because the ptr pointer points to the address of age variable and we have changed the value pointed by ptr pointer from 25 to 31. So ultimately we have changed the value of the age variable. Okay guys, we need your support to keep these types of content free for all users. YouTube really likes engagement on the video. So leave a comment below, press that like button and hit subscribe. If you haven't already, let's get the engagement score higher so that more people can discover and enjoy these courses. While working with pointers, you might encounter these two syntax of creating pointers. While both are the valid ways to create pointers, you should try to avoid the first one because this syntax sometimes creates a lot of confusion. Let's try to understand this with the help of an example. Here we have created a pointer that stores the memory address of the age variable. In this syntax, this asterisk symbol is attached to ptr. So many things that this asterisk ptr is the pointer and try to print the address using asterisk ptr which is wrong. This is because asterisk ptr gives the value pointed by the pointer not the memory address. Let me show you. I'll use printf statement here percent d comma asterisk ptr and I'll run this. As you can see we get the value of the age variable not the memory address. So to avoid this confusion, I highly recommend you to create pointer like this. Now you can visualize ptr separately as pointer and asterisk as the part of syntax to create a pointer. Now let's revise pointers. Here we have a regular variable number and pointer ptr then ptr is equals to number is wrong. This is because ptr is pointer which can only store memory address but number is not a memory address. So this is invalid. Asterisk ptr equals to ampersand number is also wrong. This is because asterisk ptr gives the value stored in the ptr location however ampersand number gives the memory address. So this is also invalid. ptr equals to ampersand number is a valid code because both ptr and ampersand number represent the memory address. So this is a valid code and asterisk ptr is equals to number. This is also valid because both asterisk ptr and number represent the value stored in the memory location. So this is also a valid code. Now to revise what we have learned in this program here is a programming task for you. Create a program to change the value of a variable using a pointer. Here is how the program should work. Get input value for a double variable salary. Assign the address of salary to a double pointer. Now use the pointer to print the value of a salary and increase the salary by two times and print the new salary. You will find the answer to this question in our github repository and also if you want to revise this concept all this program will be in there. I'll also put the link in the video description below. Now that we have reached the end of this video, it's time for programming quiz. Which of the following is valid for variable a and pointer p? Comment your answer below. See you in the next video. Happy programming!\n"
          ]
        }
      ],
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI(api_key=openai_key)\n",
        "\n",
        "audio_file = open(\"./23 C Pointers  C Programming For Beginners.mp4\", \"rb\")\n",
        "transcription = client.audio.transcriptions.create(model=\"whisper-1\", file=audio_file)\n",
        "transcription = transcription.text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have transcribed the audio to text, we need to split the text into smaller chunks. This is because with most of the LLMs we need to keep the context to a certain limit. So, we will split the text into smaller chunks and then use the LLM to generate responses. We will use `nltk` library to split the text into smaller chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting nltk\n",
            "  Downloading nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m16.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hCollecting click (from nltk)\n",
            "  Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
            "Collecting joblib (from nltk)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m40.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting regex>=2021.8.3 (from nltk)\n",
            "  Downloading regex-2024.9.11-cp311-cp311-macosx_11_0_arm64.whl (284 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.6/284.6 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in ./env/lib/python3.11/site-packages (from nltk) (4.66.5)\n",
            "Installing collected packages: regex, joblib, click, nltk\n",
            "Successfully installed click-8.1.7 joblib-1.4.2 nltk-3.9.1 regex-2024.9.11\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt_tab to\n",
            "[nltk_data]     /Users/rajesh/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk.data\n",
        "nltk.download('punkt_tab')\n",
        "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Using the tokenizer, we will split the text into smaller chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "lines = tokenizer.tokenize(transcription)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets group the sentences into smaller chunks. Something like 5 sentences in each chunk."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# group the lines array by combining 5 lines into a single string\n",
        "grouped_lines = []\n",
        "for i in range(0, len(lines), 5):\n",
        "    grouped_lines.append(\" \".join(lines[i : i + 5]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Next, we will install ChromaDB, a popular vector database, that is very convinient to use with python. We will be using in-memory mode with ChromaDB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting chromadb\n",
            "  Using cached chromadb-0.5.7-py3-none-any.whl (599 kB)\n",
            "Collecting build>=1.0.3 (from chromadb)\n",
            "  Using cached build-1.2.2-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pydantic>=1.9 in ./env/lib/python3.11/site-packages (from chromadb) (2.9.2)\n",
            "Collecting chroma-hnswlib==0.7.6 (from chromadb)\n",
            "  Using cached chroma_hnswlib-0.7.6-cp311-cp311-macosx_11_0_arm64.whl (185 kB)\n",
            "Collecting fastapi>=0.95.2 (from chromadb)\n",
            "  Using cached fastapi-0.115.0-py3-none-any.whl (94 kB)\n",
            "Collecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
            "  Using cached uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "Collecting numpy>=1.22.5 (from chromadb)\n",
            "  Using cached numpy-2.1.1-cp311-cp311-macosx_14_0_arm64.whl (5.4 MB)\n",
            "Collecting posthog>=2.4.0 (from chromadb)\n",
            "  Using cached posthog-3.6.6-py2.py3-none-any.whl (54 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in ./env/lib/python3.11/site-packages (from chromadb) (4.12.2)\n",
            "Collecting onnxruntime>=1.14.1 (from chromadb)\n",
            "  Using cached onnxruntime-1.19.2-cp311-cp311-macosx_11_0_universal2.whl (16.8 MB)\n",
            "Collecting opentelemetry-api>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_api-1.27.0-py3-none-any.whl (63 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_grpc-1.27.0-py3-none-any.whl (18 kB)\n",
            "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
            "  Using cached opentelemetry_instrumentation_fastapi-0.48b0-py3-none-any.whl (11 kB)\n",
            "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
            "  Using cached opentelemetry_sdk-1.27.0-py3-none-any.whl (110 kB)\n",
            "Collecting tokenizers>=0.13.2 (from chromadb)\n",
            "  Using cached tokenizers-0.20.0-cp311-cp311-macosx_11_0_arm64.whl (2.5 MB)\n",
            "Collecting pypika>=0.48.9 (from chromadb)\n",
            "  Using cached PyPika-0.48.9-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm>=4.65.0 in ./env/lib/python3.11/site-packages (from chromadb) (4.66.5)\n",
            "Collecting overrides>=7.3.1 (from chromadb)\n",
            "  Using cached overrides-7.7.0-py3-none-any.whl (17 kB)\n",
            "Collecting importlib-resources (from chromadb)\n",
            "  Using cached importlib_resources-6.4.5-py3-none-any.whl (36 kB)\n",
            "Collecting grpcio>=1.58.0 (from chromadb)\n",
            "  Using cached grpcio-1.66.1-cp311-cp311-macosx_10_9_universal2.whl (10.6 MB)\n",
            "Collecting bcrypt>=4.0.1 (from chromadb)\n",
            "  Using cached bcrypt-4.2.0-cp39-abi3-macosx_10_12_universal2.whl (472 kB)\n",
            "Collecting typer>=0.9.0 (from chromadb)\n",
            "  Using cached typer-0.12.5-py3-none-any.whl (47 kB)\n",
            "Collecting kubernetes>=28.1.0 (from chromadb)\n",
            "  Using cached kubernetes-31.0.0-py2.py3-none-any.whl (1.9 MB)\n",
            "Collecting tenacity>=8.2.3 (from chromadb)\n",
            "  Using cached tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
            "Collecting PyYAML>=6.0.0 (from chromadb)\n",
            "  Using cached PyYAML-6.0.2-cp311-cp311-macosx_11_0_arm64.whl (172 kB)\n",
            "Collecting mmh3>=4.0.1 (from chromadb)\n",
            "  Downloading mmh3-5.0.1-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
            "Collecting orjson>=3.9.12 (from chromadb)\n",
            "  Using cached orjson-3.10.7-cp311-cp311-macosx_10_15_x86_64.macosx_11_0_arm64.macosx_10_15_universal2.whl (251 kB)\n",
            "Requirement already satisfied: httpx>=0.27.0 in ./env/lib/python3.11/site-packages (from chromadb) (0.27.2)\n",
            "Collecting rich>=10.11.0 (from chromadb)\n",
            "  Using cached rich-13.8.1-py3-none-any.whl (241 kB)\n",
            "Requirement already satisfied: packaging>=19.1 in ./env/lib/python3.11/site-packages (from build>=1.0.3->chromadb) (24.1)\n",
            "Collecting pyproject_hooks (from build>=1.0.3->chromadb)\n",
            "  Using cached pyproject_hooks-1.1.0-py3-none-any.whl (9.2 kB)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi>=0.95.2->chromadb)\n",
            "  Downloading starlette-0.38.6-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in ./env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (4.6.0)\n",
            "Requirement already satisfied: certifi in ./env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.0.5)\n",
            "Requirement already satisfied: idna in ./env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
            "Requirement already satisfied: sniffio in ./env/lib/python3.11/site-packages (from httpx>=0.27.0->chromadb) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./env/lib/python3.11/site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
            "Requirement already satisfied: six>=1.9.0 in ./env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in ./env/lib/python3.11/site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
            "Collecting google-auth>=1.0.1 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached google_auth-2.35.0-py2.py3-none-any.whl (208 kB)\n",
            "Collecting websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached websocket_client-1.8.0-py3-none-any.whl (58 kB)\n",
            "Collecting requests (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "Collecting requests-oauthlib (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached requests_oauthlib-2.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting oauthlib>=3.2.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "Collecting urllib3>=1.24.2 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
            "Collecting durationpy>=0.7 (from kubernetes>=28.1.0->chromadb)\n",
            "  Using cached durationpy-0.7-py3-none-any.whl\n",
            "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "Collecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached protobuf-5.28.2-cp38-abi3-macosx_10_9_universal2.whl (414 kB)\n",
            "Collecting sympy (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Using cached Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
            "Collecting importlib-metadata<=8.4.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
            "  Using cached importlib_metadata-8.4.0-py3-none-any.whl (26 kB)\n",
            "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached googleapis_common_protos-1.65.0-py2.py3-none-any.whl (220 kB)\n",
            "Collecting opentelemetry-exporter-otlp-proto-common==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached opentelemetry_exporter_otlp_proto_common-1.27.0-py3-none-any.whl (17 kB)\n",
            "Collecting opentelemetry-proto==1.27.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
            "  Using cached opentelemetry_proto-1.27.0-py3-none-any.whl (52 kB)\n",
            "Collecting protobuf (from onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached protobuf-4.25.5-cp37-abi3-macosx_10_9_universal2.whl (394 kB)\n",
            "Collecting opentelemetry-instrumentation-asgi==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_instrumentation_asgi-0.48b0-py3-none-any.whl (15 kB)\n",
            "Collecting opentelemetry-instrumentation==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_instrumentation-0.48b0-py3-none-any.whl (29 kB)\n",
            "Collecting opentelemetry-semantic-conventions==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_semantic_conventions-0.48b0-py3-none-any.whl (149 kB)\n",
            "Collecting opentelemetry-util-http==0.48b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached opentelemetry_util_http-0.48b0-py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: setuptools>=16.0 in ./env/lib/python3.11/site-packages (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (65.5.0)\n",
            "Collecting wrapt<2.0.0,>=1.0.0 (from opentelemetry-instrumentation==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached wrapt-1.16.0-cp311-cp311-macosx_11_0_arm64.whl (38 kB)\n",
            "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.48b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
            "  Using cached asgiref-3.8.1-py3-none-any.whl (23 kB)\n",
            "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
            "  Using cached monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
            "  Using cached backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./env/lib/python3.11/site-packages (from pydantic>=1.9->chromadb) (2.23.4)\n",
            "Collecting markdown-it-py>=2.2.0 (from rich>=10.11.0->chromadb)\n",
            "  Using cached markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./env/lib/python3.11/site-packages (from rich>=10.11.0->chromadb) (2.18.0)\n",
            "Collecting huggingface-hub<1.0,>=0.16.4 (from tokenizers>=0.13.2->chromadb)\n",
            "  Downloading huggingface_hub-0.25.1-py3-none-any.whl (436 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m436.4/436.4 kB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click>=8.0.0 in ./env/lib/python3.11/site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Collecting shellingham>=1.3.0 (from typer>=0.9.0->chromadb)\n",
            "  Using cached shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
            "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached httptools-0.6.1-cp311-cp311-macosx_10_9_universal2.whl (145 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached uvloop-0.20.0-cp311-cp311-macosx_10_9_universal2.whl (1.3 MB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Using cached watchfiles-0.24.0-cp311-cp311-macosx_11_0_arm64.whl (367 kB)\n",
            "Collecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
            "  Downloading websockets-13.1-cp311-cp311-macosx_11_0_arm64.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.7/155.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cachetools<6.0,>=2.0.0 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached cachetools-5.5.0-py3-none-any.whl (9.5 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached pyasn1_modules-0.4.1-py3-none-any.whl (181 kB)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting filelock (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
            "  Using cached filelock-3.16.1-py3-none-any.whl (16 kB)\n",
            "Collecting fsspec>=2023.5.0 (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb)\n",
            "  Using cached fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "Collecting zipp>=0.5 (from importlib-metadata<=8.4.0,>=6.0->opentelemetry-api>=1.2.0->chromadb)\n",
            "  Using cached zipp-3.20.2-py3-none-any.whl (9.2 kB)\n",
            "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb)\n",
            "  Using cached mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached charset_normalizer-3.3.2-cp311-cp311-macosx_11_0_arm64.whl (118 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy->onnxruntime>=1.14.1->chromadb)\n",
            "  Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "Collecting pyasn1<0.7.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb)\n",
            "  Using cached pyasn1-0.6.1-py3-none-any.whl (83 kB)\n",
            "Installing collected packages: pypika, mpmath, monotonic, flatbuffers, durationpy, zipp, wrapt, websockets, websocket-client, uvloop, uvicorn, urllib3, tenacity, sympy, shellingham, PyYAML, python-dotenv, pyproject_hooks, pyasn1, protobuf, overrides, orjson, opentelemetry-util-http, oauthlib, numpy, mmh3, mdurl, importlib-resources, humanfriendly, httptools, grpcio, fsspec, filelock, charset-normalizer, cachetools, bcrypt, backoff, asgiref, watchfiles, starlette, rsa, requests, pyasn1-modules, opentelemetry-proto, markdown-it-py, importlib-metadata, googleapis-common-protos, deprecated, coloredlogs, chroma-hnswlib, build, rich, requests-oauthlib, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, onnxruntime, huggingface-hub, google-auth, fastapi, typer, tokenizers, opentelemetry-semantic-conventions, opentelemetry-instrumentation, kubernetes, opentelemetry-sdk, opentelemetry-instrumentation-asgi, opentelemetry-instrumentation-fastapi, opentelemetry-exporter-otlp-proto-grpc, chromadb\n",
            "Successfully installed PyYAML-6.0.2 asgiref-3.8.1 backoff-2.2.1 bcrypt-4.2.0 build-1.2.2 cachetools-5.5.0 charset-normalizer-3.3.2 chroma-hnswlib-0.7.6 chromadb-0.5.7 coloredlogs-15.0.1 deprecated-1.2.14 durationpy-0.7 fastapi-0.115.0 filelock-3.16.1 flatbuffers-24.3.25 fsspec-2024.9.0 google-auth-2.35.0 googleapis-common-protos-1.65.0 grpcio-1.66.1 httptools-0.6.1 huggingface-hub-0.25.1 humanfriendly-10.0 importlib-metadata-8.4.0 importlib-resources-6.4.5 kubernetes-31.0.0 markdown-it-py-3.0.0 mdurl-0.1.2 mmh3-5.0.1 monotonic-1.6 mpmath-1.3.0 numpy-2.1.1 oauthlib-3.2.2 onnxruntime-1.19.2 opentelemetry-api-1.27.0 opentelemetry-exporter-otlp-proto-common-1.27.0 opentelemetry-exporter-otlp-proto-grpc-1.27.0 opentelemetry-instrumentation-0.48b0 opentelemetry-instrumentation-asgi-0.48b0 opentelemetry-instrumentation-fastapi-0.48b0 opentelemetry-proto-1.27.0 opentelemetry-sdk-1.27.0 opentelemetry-semantic-conventions-0.48b0 opentelemetry-util-http-0.48b0 orjson-3.10.7 overrides-7.7.0 posthog-3.6.6 protobuf-4.25.5 pyasn1-0.6.1 pyasn1-modules-0.4.1 pypika-0.48.9 pyproject_hooks-1.1.0 python-dotenv-1.0.1 requests-2.32.3 requests-oauthlib-2.0.0 rich-13.8.1 rsa-4.9 shellingham-1.5.4 starlette-0.38.6 sympy-1.13.3 tenacity-9.0.0 tokenizers-0.20.0 typer-0.12.5 urllib3-2.2.3 uvicorn-0.30.6 uvloop-0.20.0 watchfiles-0.24.0 websocket-client-1.8.0 websockets-13.1 wrapt-1.16.0 zipp-3.20.2\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install chromadb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we have installed the ChromaDB, let initialize the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [],
      "source": [
        "import chromadb\n",
        "# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\n",
        "client = chromadb.Client()\n",
        "\n",
        "# Create collection. get_collection, get_or_create_collection, delete_collection also available!\n",
        "collection = client.create_collection(\"all-my-documents\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's feed the text to ChromaDB. ChromaDB will convert the text to vectors and store them in the database. Although, ChromaDB uses a smaller transformer model, it is still very powerful and can be used for a lot of NLP tasks. But for production use, you might want to use a bigger transformer model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "grouped_lines_metadata = [{\"text\": line} for line in grouped_lines]\n",
        "# use the index of the line in the grouped_lines array as the document ID\n",
        "grouped_lines_ids = [str(i) for i in range(len(grouped_lines))]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [],
      "source": [
        "collection.add(\n",
        "    documents=grouped_lines,  # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
        "    metadatas=grouped_lines_metadata,  # filter on these!\n",
        "    ids=grouped_lines_ids,  # unique for each doc\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now define a user query and get the response from the ChromaDB."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"how to read a pointers value?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = collection.query(\n",
        "    query_texts=[question],\n",
        "    n_results=2,\n",
        "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
        "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {},
      "outputs": [],
      "source": [
        "results\n",
        "import json\n",
        "context = json.dumps(results[\"documents\"], indent=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now download LangChain, a library that can be used to generate responses from the LLMs. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in ./env/lib/python3.11/site-packages (0.3.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./env/lib/python3.11/site-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in ./env/lib/python3.11/site-packages (from langchain) (2.0.35)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in ./env/lib/python3.11/site-packages (from langchain) (3.10.5)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in ./env/lib/python3.11/site-packages (from langchain) (0.3.5)\n",
            "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in ./env/lib/python3.11/site-packages (from langchain) (0.3.0)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in ./env/lib/python3.11/site-packages (from langchain) (0.1.125)\n",
            "Requirement already satisfied: numpy<2,>=1 in ./env/lib/python3.11/site-packages (from langchain) (1.26.4)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in ./env/lib/python3.11/site-packages (from langchain) (2.9.2)\n",
            "Requirement already satisfied: requests<3,>=2 in ./env/lib/python3.11/site-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./env/lib/python3.11/site-packages (from langchain) (8.5.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in ./env/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.11.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in ./env/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain) (4.12.2)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (0.27.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2024.8.30)\n",
            "Requirement already satisfied: anyio in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (4.6.0)\n",
            "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.0.5)\n",
            "Requirement already satisfied: sniffio in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain) (3.0.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Also install the openai version of langchain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.2.0-py3-none-any.whl (51 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.5/51.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: langchain-core<0.4,>=0.3 in ./env/lib/python3.11/site-packages (from langchain-openai) (0.3.5)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.40.0 in ./env/lib/python3.11/site-packages (from langchain-openai) (1.47.1)\n",
            "Collecting tiktoken<1,>=0.7 (from langchain-openai)\n",
            "  Using cached tiktoken-0.7.0-cp311-cp311-macosx_11_0_arm64.whl (907 kB)\n",
            "Requirement already satisfied: PyYAML>=5.3 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-openai) (6.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-openai) (0.1.125)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-openai) (24.1)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-openai) (2.9.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-openai) (8.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in ./env/lib/python3.11/site-packages (from langchain-core<0.4,>=0.3->langchain-openai) (4.12.2)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.6.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in ./env/lib/python3.11/site-packages (from openai<2.0.0,>=1.40.0->langchain-openai) (4.66.5)\n",
            "Requirement already satisfied: regex>=2022.1.18 in ./env/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.9.11)\n",
            "Requirement already satisfied: requests>=2.26.0 in ./env/lib/python3.11/site-packages (from tiktoken<1,>=0.7->langchain-openai) (2.32.3)\n",
            "Requirement already satisfied: idna>=2.8 in ./env/lib/python3.11/site-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.40.0->langchain-openai) (3.10)\n",
            "Requirement already satisfied: certifi in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in ./env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in ./env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.40.0->langchain-openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in ./env/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.3->langchain-openai) (3.0.0)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in ./env/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4,>=0.3->langchain-openai) (3.10.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in ./env/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4,>=0.3->langchain-openai) (2.23.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in ./env/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in ./env/lib/python3.11/site-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain-openai) (2.2.3)\n",
            "Installing collected packages: tiktoken, langchain-openai\n",
            "Successfully installed langchain-openai-0.2.0 tiktoken-0.7.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Lets now prompt the LLM with the user query and get the response. We are using a very basic prompt here. You can use more complex prompts to get better responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"    \\n    To read a pointer's value, you need to use the asterisk symbol before the pointer variable name. This will give you the value stored at the memory address pointed by the pointer.\""
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_openai import OpenAI\n",
        "\n",
        "llm = OpenAI(api_key=openai_key)\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"\n",
        "    You are a C programming instructor. you can only answer from the context that is given to you.\n",
        "    Question: {question}\n",
        "    \n",
        "    Context: {context}\n",
        "    \n",
        "    Based on the the question and the context, answer the question. Do not provide any information that is not present in the context.\n",
        "\"\"\"\n",
        ")\n",
        "\n",
        "chain = prompt | llm\n",
        "chain.invoke({\"question\": question, \"context\": context})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Conclusion\n",
        "\n",
        "In this blog post, we saw how can we build a chatbot that can help us with the information in the videos. We used the openai library to transcribe the audio to text and then used the LLM to generate responses. We also used the ChromaDB to store the text and get the responses. This is a very basic implementation of the chatbot. You can use more complex prompts and models to get better responses."
      ]
    }
  ],
  "metadata": {
    "blog_meta": {
      "author": {
        "name": "Rajesh Kumar Sharma",
        "picture": "https://cdn.thedesiloops.com/video-chat.webp"
      },
      "coverImage": "https://cdn.thedesiloops.com/video-chat.webp",
      "date": "2023-06-04T05:35:07.322Z",
      "excerpt": "In this blog post, we will see how can we build a chatbot that can help us with the information in the videos. We will use the openai library to transcribe the audio to text and then use the LLM to generate responses. We will also use the ChromaDB to store the text and get the responses.",
      "ogImage": {
        "url": "https://cdn.thedesiloops.com/video-chat.webp"
      },
      "title": "Creating a Youtube Video Chatbot using OpenAI and ChromaDB",
      "video": "https://www.youtube.com/embed/ISCLsXS9Sns"
    },
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
